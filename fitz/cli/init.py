# fitz/cli/init.py
"""
Interactive setup wizard for Fitz.

Detects available providers and creates a working configuration.
"""

from __future__ import annotations

from pathlib import Path

import typer

# Import centralized detection (THE SINGLE SOURCE OF TRUTH)
from fitz.core.detect import (
    ProviderStatus,
    detect_all,
)

# Rich for pretty output (optional, falls back gracefully)
try:
    from rich.console import Console
    from rich.panel import Panel
    from rich.prompt import Confirm, Prompt

    RICH_AVAILABLE = True
    console = Console()
except ImportError:
    RICH_AVAILABLE = False
    console = None


# =============================================================================
# Config Generation
# =============================================================================


def generate_config(
    chat_provider: str,
    embedding_provider: str,
    vector_db: str,
    qdrant_host: str = "localhost",
    qdrant_port: int = 6333,
    collection: str = "default",
    enable_rerank: bool = False,
    rerank_provider: str = "cohere",
) -> str:
    """Generate YAML config based on user choices."""

    # Chat configs - 'chat' is the canonical config key
    chat_configs = {
        "cohere": """chat:
  plugin_name: cohere
  kwargs:
    model: command-r-08-2024
    temperature: 0.2""",
        "openai": """chat:
  plugin_name: openai
  kwargs:
    model: gpt-4o-mini
    temperature: 0.2""",
        "anthropic": """chat:
  plugin_name: anthropic
  kwargs:
    model: claude-sonnet-4-20250514
    temperature: 0.2""",
        "ollama": """chat:
  plugin_name: ollama
  kwargs:
    model: llama3.2
    temperature: 0.2""",
    }

    # Embedding configs
    embedding_configs = {
        "cohere": """embedding:
  plugin_name: cohere
  kwargs:
    model: embed-english-v3.0""",
        "openai": """embedding:
  plugin_name: openai
  kwargs:
    model: text-embedding-3-small""",
        "ollama": """embedding:
  plugin_name: ollama
  kwargs:
    model: nomic-embed-text""",
    }

    # Vector DB configs
    vector_db_configs = {
        "qdrant": f"""vector_db:
  plugin_name: qdrant
  kwargs:
    host: "{qdrant_host}"
    port: {qdrant_port}""",
        "faiss": """vector_db:
  plugin_name: local-faiss
  kwargs: {}""",
    }

    # Rerank config
    rerank_config = (
        f"""rerank:
  enabled: {str(enable_rerank).lower()}
  plugin_name: {rerank_provider}
  kwargs:
    model: rerank-english-v3.0"""
        if enable_rerank
        else """rerank:
  enabled: false"""
    )

    # Build full config
    config = f"""# Fitz RAG Configuration
# Generated by: fitz init
# 
# Edit this file to customize your setup.
# Documentation: https://github.com/yafitzdev/fitz

# =============================================================================
# Chat Configuration
# =============================================================================
{chat_configs.get(chat_provider, chat_configs['cohere'])}

# =============================================================================
# Embedding Configuration  
# =============================================================================
{embedding_configs.get(embedding_provider, embedding_configs['cohere'])}

# =============================================================================
# Vector Database Configuration
# =============================================================================
{vector_db_configs.get(vector_db, vector_db_configs['qdrant'])}

# =============================================================================
# Retriever Configuration
# =============================================================================
retriever:
  plugin_name: dense
  collection: {collection}
  top_k: 5

# =============================================================================
# Reranker (improves retrieval quality)
# =============================================================================
{rerank_config}

# =============================================================================
# RGS (Retrieval-Guided Synthesis)
# =============================================================================
rgs:
  enable_citations: true
  strict_grounding: true
  max_chunks: 8
  include_query_in_context: true
  source_label_prefix: S

# =============================================================================
# Logging
# =============================================================================
logging:
  level: INFO
"""
    return config


# =============================================================================
# Display Helpers
# =============================================================================


def print_header(text: str) -> None:
    """Print a header."""
    if RICH_AVAILABLE:
        console.print(f"\n[bold blue]{text}[/bold blue]")
    else:
        print(f"\n{text}")


def print_status(name: str, available: bool, details: str = "") -> None:
    """Print status of a provider."""
    if RICH_AVAILABLE:
        icon = "‚úì" if available else "‚úó"
        color = "green" if available else "red"
        console.print(f"  [{color}]{icon}[/{color}] {name}: {details}")
    else:
        icon = "‚úì" if available else "‚úó"
        print(f"  {icon} {name}: {details}")


def print_provider_status(provider: ProviderStatus) -> None:
    """Print status for a provider using ProviderStatus dataclass."""
    print_status(provider.name, provider.available, provider.details)


def prompt_choice(prompt: str, choices: list[str], default: str = None) -> str:
    """Prompt user for a choice."""
    choices_str = "/".join(choices)
    default_str = f" ({default})" if default else ""

    while True:
        if RICH_AVAILABLE:
            response = Prompt.ask(f"{prompt} ", default=default or "", choices=choices)
        else:
            response = input(f"{prompt} [{choices_str}]{default_str}: ").strip()
            if not response and default:
                response = default

        if response in choices:
            return response

        print(f"Invalid choice. Please enter one of: {', '.join(choices)}")


def prompt_confirm(prompt: str, default: bool = True) -> bool:
    """Prompt user for yes/no."""
    if RICH_AVAILABLE:
        return Confirm.ask(prompt, default=default)
    else:
        default_str = "Y/n" if default else "y/N"
        response = input(f"{prompt} [{default_str}]: ").strip().lower()
        if not response:
            return default
        return response in ("y", "yes")


def auto_select_or_prompt(
    category: str,
    available: list[str],
    default: str,
    prompt_text: str,
) -> str:
    """
    Auto-select if only one option, otherwise prompt user.

    Args:
        category: Category name for display (e.g., "Chat", "Embedding")
        available: List of available options
        default: Default choice
        prompt_text: Text to show when prompting

    Returns:
        Selected option
    """
    if len(available) == 1:
        choice = available[0]
        if RICH_AVAILABLE:
            console.print(
                f"  [dim]{category}:[/dim] [green]{choice}[/green] [dim](auto-selected)[/dim]"
            )
        else:
            print(f"  {category}: {choice} (auto-selected)")
        return choice
    else:
        return prompt_choice(prompt_text, available, default=default)


# =============================================================================
# Main Command
# =============================================================================


def command(
    non_interactive: bool = typer.Option(
        False,
        "--non-interactive",
        "-y",
        help="Use detected defaults without prompting",
    ),
    show_config: bool = typer.Option(
        False,
        "--show-config",
        help="Only show what config would be generated",
    ),
) -> None:
    """
    Initialize Fitz with an interactive setup wizard.

    Detects available providers (API keys, Ollama, Qdrant) and
    creates a working configuration file.

    Examples:
        fitz init              # Interactive wizard
        fitz init -y           # Auto-detect and use defaults
        fitz init --show-config  # Preview config without saving
    """

    # Header
    if RICH_AVAILABLE:
        console.print(
            Panel.fit(
                "[bold]üîß Fitz Setup Wizard[/bold]\n" "Let's configure your RAG pipeline!",
                border_style="blue",
            )
        )
    else:
        print("\n" + "=" * 60)
        print("üîß Fitz Setup Wizard")
        print("Let's configure your RAG pipeline!")
        print("=" * 60)

    # ==========================================================================
    # Detection Phase (using centralized detection)
    # ==========================================================================

    print_header("Checking Chat Providers...")

    system = detect_all()

    # Display chat providers with consistent model info
    if system.api_keys["cohere"].available:
        print_status("Cohere", True, "command-r-08-2024")
    else:
        print_status("Cohere", False, "Requires COHERE_API_KEY")
    if system.api_keys["openai"].available:
        print_status("OpenAI", True, "gpt-4o-mini")
    else:
        print_status("OpenAI", False, "Requires OPENAI_API_KEY")
    if system.api_keys["anthropic"].available:
        print_status("Anthropic", True, "claude-sonnet-4-20250514")
    else:
        print_status("Anthropic", False, "Requires ANTHROPIC_API_KEY")
    if system.ollama.available:
        print_status("Ollama", True, "llama3.2")
    else:
        print_status("Ollama", False, "Not running")

    print_header("Checking Embedding Providers...")
    # Show embedding-capable providers (Anthropic doesn't have embeddings)
    if system.api_keys["cohere"].available:
        print_status("Cohere", True, "embed-english-v3.0")
    else:
        print_status("Cohere", False, "Requires COHERE_API_KEY")
    if system.api_keys["openai"].available:
        print_status("OpenAI", True, "text-embedding-3-small")
    else:
        print_status("OpenAI", False, "Requires OPENAI_API_KEY")
    if system.ollama.available:
        print_status("Ollama", True, "nomic-embed-text")
    else:
        print_status("Ollama", False, "Not running")

    print_header("Checking Rerank Providers...")
    # Currently only Cohere supports reranking
    if system.api_keys["cohere"].available:
        print_status("Cohere", True, "rerank-english-v3.0")
    else:
        print_status("Cohere", False, "Requires COHERE_API_KEY")

    print_header("Checking Vector Databases...")

    print_provider_status(system.qdrant)
    print_provider_status(system.faiss)

    # ==========================================================================
    # Determine Best Defaults (using SystemStatus helpers)
    # ==========================================================================

    chat_default = system.best_llm
    embedding_default = system.best_embedding
    vector_db_default = system.best_vector_db
    rerank_default = system.best_rerank

    # ==========================================================================
    # User Choices (if interactive)
    # ==========================================================================

    if non_interactive:
        chat_choice = chat_default
        embedding_choice = embedding_default
        vector_db_choice = vector_db_default
        collection_name = "default"
        enable_rerank = rerank_default is not None
        rerank_choice = rerank_default or "cohere"
    else:
        print_header("Configuration Options")

        # Build available lists
        available_chat = []
        if system.api_keys["cohere"].available:
            available_chat.append("cohere")
        if system.api_keys["openai"].available:
            available_chat.append("openai")
        if system.api_keys["anthropic"].available:
            available_chat.append("anthropic")
        if system.ollama.available:
            available_chat.append("ollama")

        if not available_chat:
            if RICH_AVAILABLE:
                console.print("\n[red]‚ùå No chat providers available![/red]")
                console.print(
                    "Please set an API key (COHERE_API_KEY, OPENAI_API_KEY) " "or install Ollama."
                )
            else:
                print("\n‚ùå No chat providers available!")
                print(
                    "Please set an API key (COHERE_API_KEY, OPENAI_API_KEY) " "or install Ollama."
                )
            raise typer.Exit(code=1)

        # Embedding providers (same as chat minus anthropic which doesn't have embeddings)
        available_embeddings = []
        if system.api_keys["cohere"].available:
            available_embeddings.append("cohere")
        if system.api_keys["openai"].available:
            available_embeddings.append("openai")
        if system.ollama.available:
            available_embeddings.append("ollama")

        if not available_embeddings:
            if RICH_AVAILABLE:
                console.print("\n[red]‚ùå No embedding providers available![/red]")
            else:
                print("\n‚ùå No embedding providers available!")
            raise typer.Exit(code=1)

        # Rerank providers
        available_rerank = []
        if system.api_keys["cohere"].available:
            available_rerank.append("cohere")

        # Vector DB
        available_vdbs = []
        if system.qdrant.available:
            available_vdbs.append("qdrant")
        if system.faiss.available:
            available_vdbs.append("faiss")

        if not available_vdbs:
            if RICH_AVAILABLE:
                console.print("\n[red]‚ùå No vector databases available![/red]")
                console.print("Please install FAISS (pip install faiss-cpu) or start Qdrant.")
            else:
                print("\n‚ùå No vector databases available!")
                print("Please install FAISS (pip install faiss-cpu) or start Qdrant.")
            raise typer.Exit(code=1)

        # Auto-select or prompt for each category
        chat_choice = auto_select_or_prompt(
            "Chat",
            available_chat,
            chat_default,
            "Select chat provider",
        )

        embedding_choice = auto_select_or_prompt(
            "Embedding",
            available_embeddings,
            embedding_default,
            "Select embedding provider",
        )

        # Rerank: auto-select if available, skip if not
        if available_rerank:
            if len(available_rerank) == 1:
                rerank_choice = available_rerank[0]
                enable_rerank = prompt_confirm(
                    f"Enable reranking? ({rerank_choice} available)", default=True
                )
            else:
                enable_rerank = prompt_confirm("Enable reranking?", default=True)
                if enable_rerank:
                    rerank_choice = auto_select_or_prompt(
                        "Rerank",
                        available_rerank,
                        rerank_default or "cohere",
                        "Select rerank provider",
                    )
                else:
                    rerank_choice = "cohere"
        else:
            enable_rerank = False
            rerank_choice = "cohere"
            if RICH_AVAILABLE:
                console.print(
                    "  [dim]Rerank:[/dim] [yellow]Unavailable[/yellow] [dim](requires COHERE_API_KEY)[/dim]"
                )
            else:
                print("  Rerank: Unavailable (requires COHERE_API_KEY)")

        vector_db_choice = auto_select_or_prompt(
            "Vector DB",
            available_vdbs,
            vector_db_default,
            "Select vector database",
        )

        # Collection name
        if RICH_AVAILABLE:
            collection_name = Prompt.ask("Collection name", default="default")
        else:
            collection_name = input("Collection name [default]: ").strip() or "default"

    # ==========================================================================
    # Generate Config
    # ==========================================================================

    # Get Qdrant host/port from detection
    qdrant_host = system.qdrant_host
    qdrant_port = system.qdrant_port

    config = generate_config(
        chat_provider=chat_choice,
        embedding_provider=embedding_choice,
        vector_db=vector_db_choice,
        qdrant_host=qdrant_host,
        qdrant_port=qdrant_port,
        collection=collection_name,
        enable_rerank=enable_rerank,
        rerank_provider=rerank_choice if enable_rerank else "cohere",
    )

    # ==========================================================================
    # Output
    # ==========================================================================

    print_header("Generated Configuration")

    if RICH_AVAILABLE:
        from rich.syntax import Syntax

        console.print(Syntax(config, "yaml", theme="monokai", line_numbers=False))
    else:
        print(config)

    if show_config:
        return

    # Save config
    print_header("Saving Configuration")

    # Determine save locations
    cwd = Path.cwd()
    fitz_dir = cwd / ".fitz"

    # Primary config locations that the code actually reads
    config_locations = [
        cwd / "fitz" / "engines" / "classic_rag" / "config" / "default.yaml",
        cwd / "fitz" / "pipeline" / "config" / "default.yaml",
    ]

    # Also save a copy to .fitz for reference
    fitz_config = fitz_dir / "config.yaml"

    if not non_interactive:
        # Check if any config exists
        existing = [p for p in config_locations if p.exists()]
        if existing or fitz_config.exists():
            if not prompt_confirm("Overwrite existing config files?", default=False):
                print("Aborted.")
                raise typer.Exit(code=0)

    # Create .fitz directory
    fitz_dir.mkdir(exist_ok=True)

    # Save to all locations that exist (don't create new directories)
    saved_to = []
    for config_path in config_locations:
        if config_path.parent.exists():
            config_path.write_text(config)
            saved_to.append(config_path)
            print(f"‚úì Saved to {config_path.relative_to(cwd)}")

    # Always save to .fitz/config.yaml as backup/reference
    fitz_config.write_text(config)
    saved_to.append(fitz_config)
    print(f"‚úì Saved to {fitz_config.relative_to(cwd)}")

    if not saved_to:
        print("‚ö† No config directories found - only saved to .fitz/config.yaml")

    # ==========================================================================
    # Next Steps
    # ==========================================================================

    print_header("üéâ Setup Complete!")

    next_steps = f"""
Your configuration is ready! Next steps:

1. Ingest some documents:
   fitz ingest ./your_docs {collection_name}

2. Query your documents:
   fitz query "What is in my documents?"

3. Check your setup:
   fitz doctor
"""
    print(next_steps)
