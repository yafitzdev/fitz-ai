# File: fitz/engines/classic_rag/pipeline/pipeline/engine.py
"""
RAGPipeline - Core orchestration for retrieval-augmented generation.

Flow: vector_db → retrieval → context-processing → rgs → llm → final answer
"""

from __future__ import annotations

from typing import Optional

from fitz.engines.classic_rag.config import ClassicRagConfig, load_config
from fitz.engines.classic_rag.errors.llm import LLMError
from fitz.engines.classic_rag.generation.retrieval_guided.synthesis import (
    RGS,
    RGSAnswer,
)
from fitz.engines.classic_rag.generation.retrieval_guided.synthesis import (
    RGSConfig as RGSRuntimeConfig,
)
from fitz.engines.classic_rag.pipeline.context.pipeline import ContextPipeline
from fitz.engines.classic_rag.pipeline.exceptions.pipeline import PipelineError, RGSGenerationError
from fitz.engines.classic_rag.retrieval.runtime.engine import RetrieverEngine
from fitz.llm.registry import resolve_llm_plugin
from fitz.logging.logger import get_logger
from fitz.logging.tags import PIPELINE, VECTOR_DB
from fitz.vector_db.registry import get_vector_db_plugin

logger = get_logger(__name__)


class RAGPipeline:
    """
    RAG Pipeline orchestrator.

    Flow: vector_db → retrieval → context-processing → rgs → llm → final answer

    Usage:
        >>> from fitz.engines.classic_rag.config import load_config
        >>> config = load_config()
        >>> pipeline = RAGPipeline.from_config(config)
        >>> answer = pipeline.run("What is quantum computing?")
    """

    def __init__(
        self,
        retriever: RetrieverEngine,
        llm,  # Chat plugin directly
        rgs: RGS,
        context: ContextPipeline | None = None,
    ):
        self.retriever = retriever
        self.llm = llm
        self.rgs = rgs
        self.context = context or ContextPipeline()

        logger.info(f"{PIPELINE} RAGPipeline initialized")

    def run(self, query: str) -> RGSAnswer:
        """
        Execute the RAG pipeline for a query.

        Args:
            query: The user's question

        Returns:
            RGSAnswer with answer text and source references
        """
        logger.info(f"{PIPELINE} Running pipeline for query='{query[:50]}...'")

        # Step 1: Retrieve relevant chunks
        try:
            raw_chunks = self.retriever.retrieve(query)
        except Exception as exc:
            logger.error(f"{PIPELINE} Retriever failed: {exc}")
            raise PipelineError("Retriever failed") from exc

        # Step 2: Process context (dedupe, group, merge, pack)
        try:
            chunks = self.context.process(raw_chunks)
        except Exception as exc:
            logger.error(f"{PIPELINE} Context processing failed: {exc}")
            raise PipelineError("Context processing failed") from exc

        # Step 3: Build RGS prompt
        try:
            prompt = self.rgs.build_prompt(query, chunks)
        except Exception as exc:
            logger.error(f"{PIPELINE} Failed to build RGS prompt: {exc}")
            raise RGSGenerationError("Failed to build RGS prompt") from exc

        # Step 4: Generate answer via LLM
        messages = [
            {"role": "system", "content": prompt.system},
            {"role": "user", "content": prompt.user},
        ]

        try:
            raw = self.llm.chat(messages)
        except Exception as exc:
            logger.error(f"{PIPELINE} LLM chat failed: {exc}")
            raise LLMError("LLM chat operation failed") from exc

        # Step 5: Structure the answer
        try:
            answer = self.rgs.build_answer(raw, chunks)
            logger.info(f"{PIPELINE} Pipeline run completed")
            return answer
        except Exception as exc:
            logger.error(f"{PIPELINE} Failed to structure RGS answer: {exc}")
            raise RGSGenerationError("Failed to build RGS answer") from exc

    @classmethod
    def from_config(cls, cfg: ClassicRagConfig) -> "RAGPipeline":
        """
        Create a RAGPipeline from configuration.

        This is the primary factory method for creating pipelines.

        Args:
            cfg: ClassicRagConfig with all pipeline settings

        Returns:
            Configured RAGPipeline instance
        """
        logger.info(f"{PIPELINE} Constructing RAGPipeline from config")

        # Vector DB - YAML plugin system
        vector_client = get_vector_db_plugin(
            cfg.vector_db.plugin_name,
            **cfg.vector_db.kwargs
        )
        logger.info(f"{VECTOR_DB} Using vector DB plugin='{cfg.vector_db.plugin_name}'")

        # Chat LLM - use plugin directly
        ChatCls = resolve_llm_plugin(
            plugin_type="chat",
            requested_name=cfg.chat.plugin_name,
        )
        chat_plugin = ChatCls(**cfg.chat.kwargs)

        # Embedding - use plugin directly
        EmbedCls = resolve_llm_plugin(
            plugin_type="embedding",
            requested_name=cfg.embedding.plugin_name,
        )
        embedder = EmbedCls(**cfg.embedding.kwargs)

        # Rerank (optional) - use plugin directly
        rerank_plugin = None
        if cfg.rerank.enabled:
            RerankCls = resolve_llm_plugin(
                plugin_type="rerank",
                requested_name=cfg.rerank.plugin_name,
            )
            rerank_plugin = RerankCls(**cfg.rerank.kwargs)

        # Retriever
        retriever = RetrieverEngine.from_name(
            cfg.retriever.plugin_name,
            client=vector_client,
            retriever_cfg=cfg.retriever,
            embedder=embedder,
            rerank_engine=rerank_plugin,
        )

        # RGS
        rgs_cfg = RGSRuntimeConfig(
            enable_citations=cfg.rgs.enable_citations,
            strict_grounding=cfg.rgs.strict_grounding,
            answer_style=cfg.rgs.answer_style,
            max_chunks=cfg.rgs.max_chunks,
            max_answer_chars=cfg.rgs.max_answer_chars,
            include_query_in_context=cfg.rgs.include_query_in_context,
            source_label_prefix=cfg.rgs.source_label_prefix,
        )
        rgs = RGS(config=rgs_cfg)

        logger.info(f"{PIPELINE} RAGPipeline successfully created")
        return cls(retriever=retriever, llm=chat_plugin, rgs=rgs, context=ContextPipeline())

    @classmethod
    def from_dict(cls, config_dict: dict) -> "RAGPipeline":
        """
        Create a RAGPipeline from a configuration dictionary.

        Args:
            config_dict: Configuration dictionary matching ClassicRagConfig schema

        Returns:
            RAGPipeline instance
        """
        logger.info(f"{PIPELINE} Creating RAGPipeline from dict")
        cfg = ClassicRagConfig.from_dict(config_dict)
        return cls.from_config(cfg)


def create_pipeline_from_yaml(path: Optional[str] = None) -> RAGPipeline:
    """
    Create a RAGPipeline from a YAML config file.

    Args:
        path: Path to YAML config file. If None, uses default config.

    Returns:
        Configured RAGPipeline instance
    """
    cfg = load_config(path)
    return RAGPipeline.from_config(cfg)