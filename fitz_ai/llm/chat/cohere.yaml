# fitz_ai/llm/chat/cohere.yaml
#
# Cohere Chat Plugin - v2 Chat API
# Documentation: https://docs.cohere.com/reference/chat
#
# Available models (as of 2025):
#   - command-a-03-2025       (newest, best performance)
#   - command-r-plus-08-2024  (powerful, complex tasks)
#   - command-r-08-2024       (efficient, general purpose)
#
# IMPORTANT: This plugin is configured for Cohere v2 API which uses:
#   - OpenAI-compatible messages format (messages array with role/content)
#   - Response in message.content[0].text format

# =============================================================================
# IDENTITY
# =============================================================================
plugin_name: "cohere"
plugin_type: "chat"
version: "2.0"

# =============================================================================
# PROVIDER
# =============================================================================
provider:
  name: "cohere"
  base_url: "https://api.cohere.ai/v2"

# =============================================================================
# AUTHENTICATION
# =============================================================================
auth:
  type: "bearer"
  header_name: "Authorization"
  header_format: "Bearer {key}"
  env_vars:
    - "COHERE_API_KEY"

# =============================================================================
# REQUIRED ENVIRONMENT VARIABLES (optional section)
# =============================================================================
required_env: []

# =============================================================================
# HEALTH CHECK (optional section)
# =============================================================================
health_check: null

# =============================================================================
# ENDPOINT
# =============================================================================
endpoint:
  path: "/chat"
  method: "POST"
  timeout: 120

# =============================================================================
# DEFAULTS
# =============================================================================
# Models are split by tier:
#   smart: Best quality for user-facing responses (queries)
#   fast: Best speed for background tasks (enrichment, summaries)
#   balanced: Cost-effective with good quality (evaluation, bulk tasks)
defaults:
  models:
    smart: "command-a-03-2025"
    fast: "command-r7b-12-2024"
    balanced: "command-r7b-12-2024"
  temperature: 0.2
  max_tokens: null

# =============================================================================
# REQUEST CONFIGURATION
# =============================================================================
# Cohere v2 API uses OpenAI-compatible message format:
#   {"messages": [{"role": "system", "content": "..."}, {"role": "user", "content": "..."}]}
request:
  messages_transform: "cohere_chat"
  static_fields:
    stream: false
  param_map:
    model: "model"
    temperature: "temperature"
    max_tokens: "max_tokens"

# =============================================================================
# RESPONSE CONFIGURATION
# =============================================================================
# Cohere v2 API response format:
#   {
#     "message": {
#       "role": "assistant",
#       "content": [{"type": "text", "text": "Response here..."}]
#     }
#   }
response:
  content_path: "message.content[0].text"
  is_array: false
  array_index: 0
  metadata_paths:
    finish_reason: "finish_reason"
    tokens_input: "usage.billed_units.input_tokens"
    tokens_output: "usage.billed_units.output_tokens"