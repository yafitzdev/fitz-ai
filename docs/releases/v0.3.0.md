# Release Notes - v0.3.0

**Release Date**: December 17, 2024

---

## ğŸ‰ Overview

Fitz v0.3.0 is a **major architectural release** that transforms Fitz from a RAG framework into a **multi-engine knowledge platform**. This release introduces pluggable engine support, the CLaRa engine for compression-native RAG, and a universal runtime for seamless engine switching.

---

## âœ¨ Highlights

### ğŸ”Œ Multi-Engine Architecture

Switch between knowledge paradigms with a single parameter:

```python
from fitz import run

# Fitz RAG
answer = run("What is X?", engine="fitz_rag")

# CLaRa (compression-native RAG)
answer = run("What is X?", engine="clara")

# Your custom engine
answer = run("What is X?", engine="my_custom")
```

### ğŸ§  CLaRa Engine (NEW)

Apple's Continuous Latent Reasoning engine is now available:

- **16x-128x document compression** while preserving semantics
- **Unified retrieval-generation** in latent space
- **Superior multi-hop reasoning** performance
- **No separate embedding model** needed

```python
from fitz_ai.engines.clara import run_clara

answer = run_clara(
    "How do these concepts relate?",
    documents=my_large_document_set
)
```

### ğŸ¯ Universal Runtime

One API to rule them all:

```python
from fitz import run
from fitz_ai.runtime import list_engines, create_engine

# Discover available engines
print(list_engines())  # ['fitz_rag', 'clara']

# Create reusable engine
engine = create_engine(engine="clara")

# Universal query interface
answer = run("Question?", engine="clara")
```

### ğŸ”§ Custom Engine Support

Create your own engine in minutes:

```python
from fitz_ai.core import Query, Answer, Provenance
from fitz_ai.runtime import EngineRegistry

class MyEngine:
    def answer(self, query: Query) -> Answer:
        # Your logic here
        return Answer(text="...", provenance=[...])

# Register and use
EngineRegistry.get_global().register("my_engine", lambda c: MyEngine())
answer = run("Question?", engine="my_engine")
```

---

## ğŸ“¦ What's New

### Core Contracts

| Type | Description |
|------|-------------|
| `KnowledgeEngine` | Protocol all engines implement |
| `Query` | Standardized query with constraints |
| `Answer` | Standardized response with provenance |
| `Provenance` | Source attribution |
| `Constraints` | Query-time limits |

### New Engines

| Engine | Description | Status |
|--------|-------------|--------|
| `fitz_rag` | Traditional RAG | âœ… Production |
| `clara` | CLaRa compression-native RAG | âœ… Available |
| `graphrag` | Knowledge graph RAG | ğŸ”œ Planned |

### Runtime Functions

```python
from fitz import run
from fitz_ai.runtime import (
    create_engine,
    list_engines,
    list_engines_with_info,
    get_engine_registry,
)
```

---

## ğŸš€ Getting Started

### Installation

```bash
# Base installation
pip install fitz_ai

# With CLaRa support
pip install fitz_ai[clara]
```

### Quick Start

```python
from fitz import run

# Simple query (uses fitz_rag by default)
answer = run("What is quantum computing?")
print(answer.text)

# Switch to CLaRa
answer = run("Explain the relationship between X, Y, and Z", engine="clara")
print(answer.text)
```

### Using CLaRa

```python
from fitz_ai.engines.clara import run_clara, create_clara_engine

# Quick query with documents
answer = run_clara(
    "Summarize the key findings",
    documents=my_research_papers
)

# Reusable engine
engine = create_clara_engine()
engine.add_documents(my_documents)
answer = engine.answer(Query(text="What patterns emerge?"))
```

---

## âš ï¸ Breaking Changes

### Import Paths

| Old (v0.2.x) | New (v0.3.0) |
|--------------|--------------|
| `from fitz_ai.pipeline.pipeline.engine import RAGPipeline` | `from fitz_ai.engines.fitz_rag import run_fitz_rag` |
| `from fitz_ai.pipeline.config.loader import load_config` | `from fitz_ai.engines.fitz_rag.config import load_config` |
| `from fitz_ai.core.llm` | `from fitz_ai.llm` |

### API Changes

```python
# OLD
result = pipeline.run("query")
print(result.answer)
print(result.sources)

# NEW
answer = run_fitz_rag("query")
print(answer.text)
print(answer.provenance)
```

### Migration

See [MIGRATION.md](MIGRATION.md) for detailed upgrade instructions.

---

## ğŸ”§ Configuration

### Fitz RAG (unchanged)

```yaml
llm:
  plugin_name: openai
  kwargs:
    model: gpt-4

embedding:
  plugin_name: openai

vector_db:
  plugin_name: qdrant
```

### CLaRa (new)

```yaml
clara:
  model:
    model_name_or_path: "apple/CLaRa-7B-E2E"
    variant: "e2e"
    device: "cuda"
  compression:
    compression_rate: 16
  retrieval:
    top_k: 5
```

---

## ğŸ“Š Performance

### CLaRa vs Fitz RAG

| Metric | Fitz RAG | CLaRa |
|--------|-------------|-------|
| Context tokens | ~4000 | ~250 (16x compression) |
| Multi-hop accuracy | Baseline | +15-20% |
| Memory usage | Higher | Lower |
| Setup complexity | Multiple models | Single model |

---

## ğŸ› ï¸ Developer Experience

### Creating Custom Engines

```python
# 1. Implement the protocol
class MyEngine:
    def answer(self, query: Query) -> Answer:
        return Answer(text="...", provenance=[])

# 2. Register
registry = EngineRegistry.get_global()
registry.register("my_engine", lambda c: MyEngine())

# 3. Use
answer = run("Question?", engine="my_engine")
```

### Testing

All 155 tests passing:
- Core contracts
- Fitz RAG engine
- CLaRa engine
- Universal runtime
- Engine registry

---

## ğŸ“š Documentation

- [README.md](README.md) - Overview and quick start
- [MIGRATION.md](MIGRATION.md) - Upgrade guide
- [ENGINES.md](ENGINES.md) - Engine architecture
- [CUSTOM_ENGINES.md](CUSTOM_ENGINES.md) - Creating engines
- [CHANGELOG.md](CHANGELOG.md) - Full changelog

---

## ğŸ™ Acknowledgments

- Apple ML team for the [CLaRa paper](https://arxiv.org/abs/2511.18659) and models
- All contributors and early adopters

---

## ğŸ“ Support

- **Issues**: https://github.com/yafitzdev/fitz-ai/issues
- **Discussions**: https://github.com/yafitzdev/fitz-ai/discussions
- **Documentation**: https://fitz.readthedocs.io

---

**Happy building! ğŸš€**