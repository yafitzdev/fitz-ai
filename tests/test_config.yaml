# tests/test_config.yaml
# Unified test configuration - ALL tests use this

# Embedding (local Ollama - bge-m3 has 16k context vs 8k for nomic)
embedding: local_ollama
embedding_kwargs:
  model: bge-m3

# Vector DB
vector_db: local_faiss
vector_db_kwargs: {}

# Tiered chat execution (local -> cloud fallback)
tiers:
  - name: local
    chat: local_ollama
    chat_kwargs:
      models:
        smart: qwen2.5:7b
        fast: qwen2.5:1.5b
        balanced: qwen2.5:3b

  - name: cloud
    chat: cohere
    chat_kwargs:
      models:
        smart: command-a-03-2025
        fast: command-r7b-12-2024
        balanced: command-r-08-2024

# Response cache (E2E)
cache:
  enabled: true
  max_entries: 1000
  ttl_days: 30
